{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "**Fachprojekt Dokumentenanalyse** *SS24* -- *Arthur Matei, Gernot A. Fink* -- *Technische UniversitÃ¤t Dortmund, Lehrstuhl XII, Mustererkennung*\n",
        "---\n",
        "# Aufgabe 2: Bag-of-Words, Klassifikation\n",
        "\n",
        "In dieser Aufgabe sollen unbekannte Dokumente zu bekannten Kategorien automatisch zugeordnet werden.\n",
        "\n",
        "Die dabei erforderlichen numerischen Berechnungen lassen sich im Vergleich zu einer direkten Implementierung in Python erheblich einfacher mit NumPy / SciPy durchfuehren. Die folgende Aufgabe soll Ihnen die Unterschiede anhand eines kleinen Beispiels verdeutlichen.\n",
        "\n",
        "Geben Sie fuer jede Katgorie des Brown Corpus die durchschnittliche Anzahl von Woertern pro Dokument aus. Bestimmen Sie auch die Standardabweichung. Stellen Sie diese Statistik mit einem bar plot dar. Verwenden Sie dabei auch Fehlerbalken (siehe visualization.hbar_plot)\n",
        "\n",
        "Berechnen Sie Mittelwert und Standardabweichung jeweils:\n",
        "\n",
        " - nur mit Python Funktion\n",
        "   hilfreiche Funktionen: sum, float, math.sqrt, math.pow\n",
        "\n",
        " - mit NumPy\n",
        "   hilfreiche Funktionen: np.array, np.mean, np.std\n",
        "\n",
        "http://docs.python.org/3/library/math.html\n",
        "http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html\n",
        "http://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ipympl'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwidget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mpath:\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/magics/pylab.py:103\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;241m%\u001b[39m _list_matplotlib_backends_and_gui_loops()\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_matplotlib_backend(args\u001b[38;5;241m.\u001b[39mgui, backend)\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py:3677\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3673\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWarning: Cannot change to a different GUI toolkit: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   3674\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (gui, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select))\n\u001b[1;32m   3675\u001b[0m         gui, backend \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mfind_gui_and_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select)\n\u001b[0;32m-> 3677\u001b[0m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivate_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3679\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib_inline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_inline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_inline_support\n\u001b[1;32m   3681\u001b[0m configure_inline_support(\u001b[38;5;28mself\u001b[39m, backend)\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/pylabtools.py:408\u001b[0m, in \u001b[0;36mactivate_matplotlib\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# Due to circular imports, pyplot may be only partially initialised\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# when this function runs.\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# So avoid needing matplotlib attribute-lookup to access pyplot.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m--> 408\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswitch_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow\u001b[38;5;241m.\u001b[39m_needmain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# We need to detect at runtime whether show() is called by the user.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# For this, we wrap it into a decorator which adds a 'called' flag.\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/pyplot.py:342\u001b[0m, in \u001b[0;36mswitch_backend\u001b[0;34m(newbackend)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# have to escape the switch on access logic\u001b[39;00m\n\u001b[1;32m    340\u001b[0m old_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(rcParams, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 342\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_module_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewbackend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m canvas_class \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mFigureCanvas\n\u001b[1;32m    345\u001b[0m required_framework \u001b[38;5;241m=\u001b[39m canvas_class\u001b[38;5;241m.\u001b[39mrequired_interactive_framework\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:992\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipympl'"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib widget\n",
        "\n",
        "import sys\n",
        "\n",
        "if \"..\" not in sys.path:\n",
        "    sys.path.append(\"..\")\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "from common.corpus import CorpusLoader\n",
        "from common.visualization import hbar_plot\n",
        "\n",
        "# Laden des Brown Corpus\n",
        "CorpusLoader.load()\n",
        "brown = CorpusLoader.brown_corpus()\n",
        "brown_categories = brown.categories()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        " ## Klassifikation von Dokumenten\n",
        "\n",
        "Nachdem Sie sich nun mit der Struktur und den Eigenschaften des Brown Corpus vertraut gemacht haben, soll er die Datengrundlage fuer die Evaluierung von Algorithmen zur automatischen Klassifikation von Dokumenten bilden.\n",
        "In der Regel bestehen diese Algorithmen aus drei Schritten:\n",
        " - Vorverarbeitung\n",
        " - Merkmalsberechnung\n",
        " - Klassifikation\n",
        "\n",
        "Bei der Anwendung auf Dokumente (Texte) werden diese Schritte wie folgt umgesetzt:\n",
        "\n",
        " - **Vorverarbeitung:** Filterung von stopwords und Abbildung von Woertern auf Wortstaemme.\n",
        " - **Merkmalsberechnung:** Jedes Dokument wird numerisch durch einen Vektor repraesentiert (--> NumPy), der moeglichst die bzgl. der Klassifikation bedeutungsunterscheidenden Informationen enthaehlt.\n",
        " - **Klassifikation:** Jedem Merkmalsvektor (Dokument) wird ein Klassenindex (Kategorie) zugeordnet.\n",
        "\n",
        "Details finden Sie zum Beispiel in:\n",
        "http://www5.informatik.uni-erlangen.de/fileadmin/Persons/NiemannHeinrich/klassifikation-von-mustern/m00-www.pdf (section 1.3)\n",
        "\n",
        "Eine sehr verbreitete Merkmalsrepraesentation fuer (textuelle) Dokumente sind sogenannte Bag-of-Words. Dabei wird jedes Dokument durch ein Histogram (Verteilung) ueber Wortfrequenzen repraesentiert. Man betrachtet dazu das Vorkommen von 'typischen' Woertern, die durch ein Vokabular gegeben sind.\n",
        "\n",
        "Bestimmen Sie ein Vokabular, also die typischen Woerter, fuer den Brown Corpus. Berechnen Sie dazu die 500 haeufigsten Woerter (nach stemming und Filterung von stopwords und Satzzeichen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from common.features import BagOfWords, WordListNormalizer\n",
        "# vocabulary =\n",
        "\n",
        "print('Filtering and stemming words in corpus...')\n",
        "normalizer = WordListNormalizer()\n",
        "category_wordlists_dict = normalizer.category_wordlists_dict(corpus=brown)\n",
        "# Flatten the category word lists for computing overall word frequencies\n",
        "# The * operator expands the list/iterator to function arguments\n",
        "# itertools.chain concatenates all its parameters to a single list\n",
        "print('Building Bag-of-Words vocabulary...')\n",
        "wordlists = itertools.chain(*(iter(category_wordlists_dict.values())))\n",
        "words = itertools.chain(*wordlists)\n",
        "\n",
        "vocabulary_complete = BagOfWords.most_freq_words(words)\n",
        "vocabulary = vocabulary_complete[:500]\n",
        "#@DELETE_END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Berechnen Sie Bag-of-Words Repraesentationen fuer jedes Dokument des Brown Corpus. Verwenden Sie absolute Frequenzen. speichern Sie die Bag-of-Word Repraesentationen fuer jede Kategorie in einem 2-D NumPy Array. Speichern Sie den Bag-of-Words Vektor fuer jedes Dokument in einer Zeile, so dass das Array (ndarray) folgende Dimension hat:\n",
        "\n",
        " |Dokument_kat| X |Vokabular|\n",
        "\n",
        "|Dokument_kat| entspricht der Anzahl Dokumente einer Kategorie.\n",
        "|Vokabular| entspricht der Anzahl Woerter im Vokabular (hier 500).\n",
        "\n",
        "Eine einfache Zuordnung von Kategorie und Bag-of-Words Matrix ist durch ein Dictionary moeglich.\n",
        "\n",
        "Implementieren Sie die Funktion BagOfWords.category_bow_dict im Modul features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print('Building Bag-of-Words feature vector representations...')\n",
        "bow = BagOfWords(vocabulary)\n",
        "category_bow_dict = bow.category_bow_dict(category_wordlists_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testen Sie ihre Implementierung mit folgendem Unittest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import unittest\n",
        "\n",
        "from utest.test_features import BagOfWordsTest\n",
        "\n",
        "suite = unittest.TestSuite()\n",
        "suite.addTest(BagOfWordsTest(\"test_category_bow_dict\"))\n",
        "runner = unittest.TextTestRunner()\n",
        "runner.run(suite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Um einen Klassifikator statistisch zu evaluieren, benoetigt man eine Trainingsstichprobe und eine Teststichprobe der Daten die klassifiziert werden sollen. Die Trainingsstichprobe benoetigt man zum Erstellen oder Trainieren des Klassifikators. Dabei werden in der Regel die Modellparameter des Klassifikators statistisch aus den Daten der Traingingsstichprobe geschaetzt. Die Klassenzugehoerigkeiten sind fuer die Beispiele aus der Trainingsstichprobe durch so genannte Klassenlabels gegeben.\n",
        "\n",
        "Nachdem man den Klassifikator trainiert hat, interessiert man sich normalerweise dafuer wie gut er sich unter realen Bedingung verhaelt. Das heisst, dass der Klassifikator bei der Klassifikation zuvor unbekannter Daten moeglichst wenige Fehler machen soll. Dies simuliert man mit der Teststichprobe. Da auch fuer jedes Beispiel aus der Teststichprobe die Klassenzugehoerigkeit bekannt ist, kann man am Ende die Klassifikationsergebnisse mit den wahren Klassenlabels (aus der Teststichprobe) vergleichen und eine Fehlerrate angeben.\n",
        "\n",
        "In dem gegebenen Brown Corpus ist keine Aufteilung in Trainings und Testdaten vorgegeben.\n",
        "\n",
        "Waehlen Sie daher die ersten 80% der Dokumente UEBER ALLE KATEGORIEN als Trainingstichprobe und die letzten 20% der Dokumente UEBER ALLE KATEGORIEN als Teststichprobe.\n",
        "\n",
        "Erklaeren Sie, warum Sie die Stichproben ueber alle Kategorien zusammenstellen MUESSEN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Antwort:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bitte beachten Sie, dass wir im Rahmen des Fachprojekts keinen Test auf unbekannten Testdaten simulieren. Wir haben ja bereits fuer die Erstellung der Vokabulars (haeufigste Woerter, siehe oben) den kompletten Datensatz verwendet. Stattdessen betrachten wir hier ein so genanntes Validierungsszenario, in dem wir die Klassifikationsleistung auf dem Brown Corpus optimieren. Die Ergebnisse lassen sich somit nur sehr bedingt auf unbekannte Daten uebertragen.\n",
        "\n",
        "Erstellen Sie nun die NumPy Arrays train_samples, train_labels, test_samples und test_labels, so dass diese mit den estimate und classify Methoden der Klassen im classificaton Modul verwendet werden koennen. Teilen Sie die Daten wie oben angegeben zu 80% in Trainingsdaten und 20% in Testdaten auf.\n",
        "\n",
        "Hinweis: Vollziehen Sie nach, wie die Klasse CrossValidation im evaluation Modul funktioniert. Wenn Sie moechten, koennen die Klasse zur Aufteilung der Daten verwenden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from common.evaluation import CrossValidation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Klassifizieren Sie nun alle Dokumente der Teststichprobe nach dem Prinzip des k-naechste-Nachbarn Klassifikators. Dabei wird die Distanz zwischen dem Merkmalsvektors eines Testbeispiels und allen Merkmalsvektoren aus der Trainingstichprobe berechnet. Das Klassenlabel des Testbeispiels wird dann ueber einen Mehrheitsentscheid der Klassenlabels der k aehnlichsten Merkmalsvektoren aus der Trainingsstichprobe bestimmt.\n",
        "\n",
        "http://www5.informatik.uni-erlangen.de/fileadmin/Persons/NiemannHeinrich/klassifikation-von-mustern/m00-www.pdf (Abschnitt 4.2.7)\n",
        "\n",
        "Bestimmen Sie die Distanzen von Testdaten zu Trainingsdaten mit cdist:\n",
        "http://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html\n",
        "Bestimmen Sie die k-naechsten Nachbarn auf Grundlage der zuvor berechneten Distanzen mit argsort:\n",
        "http://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html\n",
        "Ueberlegen Sie, welche zuvor von Ihnen implementierte Funktion Sie wiederverwenden koennen, um den Mehrheitsentscheid umzusetzen.\n",
        "\n",
        "Implementieren Sie die Funktionen estimate und classify in der Klasse KNNClassifier im Modul classification.\n",
        "\n",
        "Verwenden Sie die Euklidische Distanz und betrachten Sie zunaechst nur den naechsten Nachbarn (k=1).\n",
        "\n",
        "HINWEIS: Hier ist zunaechst nur die Implementierung eines naechster Nachbar Klassifikators erforderlich. Diese soll aber in der naechsten Aufgabe zu einer Implementierung eines k-naechste Nachbarn Klassifikators erweitert werden. Beruechsichtigen Sie das in ihrer Implementierung.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from common.classification import KNNClassifier\n",
        "\n",
        "knn_classifier = KNNClassifier(k_neighbors=1, metric='euclidean')\n",
        "knn_classifier.estimate(train_bow, train_labels)\n",
        "knn_test_labels = knn_classifier.classify(test_bow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testen Sie ihre Implementierung mit folgendem Unittest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import unittest\n",
        "\n",
        "from utest.test_classification import ClassificationTest\n",
        "\n",
        "suite = unittest.TestSuite()\n",
        "suite.addTest(ClassificationTest(\"test_nn\"))\n",
        "runner = unittest.TextTestRunner()\n",
        "runner.run(suite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Nachdem Sie mit dem KNNClassifier fuer jedes Testbeispiel ein Klassenlabel geschaetzt haben, koennen Sie dieses mit dem tatsaechlichen Klassenlabel vergleichen. Dieses koennen Sie wie bei den Traingingsdaten dem Corpus entnehmen.\n",
        "\n",
        "Ermitteln Sie eine Gesamtfehlerrate und je eine Fehlerrate pro Kategorie. Implementieren Sie dazu die Klasse ClassificationEvaluator im evaluation Modul.\n",
        "\n",
        "Warum ist diese Aufteilung der Daten in Training und Test problematisch? Was sagen die Ergebnisse aus?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from common.evaluation import ClassificationEvaluator\n",
        "\n",
        "classification_eval = ClassificationEvaluator(knn_test_labels, test_labels)\n",
        "err, n_wrong, n_sampels = classification_eval.error_rate()\n",
        "category_error_rates = classification_eval.category_error_rates()\n",
        "print('Classification error rates: ( n_wrong, n_samples ) error_rate')\n",
        "print('   Overall        : ( {:2} / {:2} ) {:.2f}'.format(n_wrong, n_sampels, err))\n",
        "print('Class specific :')\n",
        "for category, err, n_wrong, n_samples in category_error_rates:\n",
        "    print('   {:15}: ( {:2} / {:2} ) {:.2f}'.format(category, n_wrong, n_samples, err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Testen Sie ihre Implementierung mit folgendem Unittest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import unittest\n",
        "\n",
        "from utest.test_evaluation import ClassificationEvaluatorTest\n",
        "unittest.main(ClassificationEvaluatorTest(), argv=[''], exit=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
