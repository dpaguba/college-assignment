{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37aa0e56",
   "metadata": {},
   "source": [
    "**Fachprojekt Dokumentenanalyse** *SS 24* -- *Arthur Matei, Gernot A. Fink* -- *TU Dortmund, LS12, Arbeitsgruppe Mustererkennung*\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af61ab2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Aufgabe 2: Bag-of-Words, Klassifikation\n",
    "\n",
    "In dieser Aufgabe sollen unbekannte Dokumente zu bekannten Kategorien automatisch zugeordnet werden.\n",
    "\n",
    "Die dabei erforderlichen numerischen Berechnungen lassen sich im Vergleich zu einer direkten Implementierung in Python erheblich einfacher mit NumPy / SciPy durchfuehren. Die folgende Aufgabe soll Ihnen die Unterschiede anhand eines kleinen Beispiels verdeutlichen.\n",
    "\n",
    "Geben Sie fuer jede Katgorie des Brown Corpus die durchschnittliche Anzahl von Woertern pro Dokument aus. Bestimmen Sie auch die Standardabweichung. Stellen Sie diese Statistik mit einem bar plot dar. Verwenden Sie dabei auch Fehlerbalken (siehe visualization.hbar_plot)\n",
    "\n",
    "Berechnen Sie Mittelwert und Standardabweichung jeweils:\n",
    "\n",
    " - nur mit Python Funktion\n",
    "   hilfreiche Funktionen: sum, float, math.sqrt, math.pow\n",
    "\n",
    " - mit NumPy\n",
    "   hilfreiche Funktionen: np.array, np.mean, np.std\n",
    "\n",
    "http://docs.python.org/3/library/math.html\n",
    "http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html\n",
    "http://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c655af27",
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c1b2dbe46d727262d2865641f332acb",
     "grade": true,
     "grade_id": "cell-6dc0b97c1dfe9e6b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kategorie: adventure\n",
      "Mittelwert: 2391.103448275862\n",
      "Standardabweichung: 76.95244605356373\n",
      "\n",
      "Kategorie: belles_lettres\n",
      "Mittelwert: 2307.9466666666667\n",
      "Standardabweichung: 64.64691657165268\n",
      "\n",
      "Kategorie: editorial\n",
      "Mittelwert: 2281.6296296296296\n",
      "Standardabweichung: 48.05332543173272\n",
      "\n",
      "Kategorie: fiction\n",
      "Mittelwert: 2361.655172413793\n",
      "Standardabweichung: 71.55864528221204\n",
      "\n",
      "Kategorie: government\n",
      "Mittelwert: 2337.233333333333\n",
      "Standardabweichung: 98.64977896016235\n",
      "\n",
      "Kategorie: hobbies\n",
      "Mittelwert: 2287.3611111111113\n",
      "Standardabweichung: 57.442798977077956\n",
      "\n",
      "Kategorie: humor\n",
      "Mittelwert: 2410.5555555555557\n",
      "Standardabweichung: 96.29827633291967\n",
      "\n",
      "Kategorie: learned\n",
      "Mittelwert: 2273.6\n",
      "Standardabweichung: 66.50537572256847\n",
      "\n",
      "Kategorie: lore\n",
      "Mittelwert: 2297.8958333333335\n",
      "Standardabweichung: 59.243930625611114\n",
      "\n",
      "Kategorie: mystery\n",
      "Mittelwert: 2382.0416666666665\n",
      "Standardabweichung: 55.38236720493467\n",
      "\n",
      "Kategorie: news\n",
      "Mittelwert: 2285.318181818182\n",
      "Standardabweichung: 49.49920693913495\n",
      "\n",
      "Kategorie: religion\n",
      "Mittelwert: 2317.5882352941176\n",
      "Standardabweichung: 57.065554484737284\n",
      "\n",
      "Kategorie: reviews\n",
      "Mittelwert: 2394.3529411764707\n",
      "Standardabweichung: 74.93443500936675\n",
      "\n",
      "Kategorie: romance\n",
      "Mittelwert: 2414.551724137931\n",
      "Standardabweichung: 91.73484511008986\n",
      "\n",
      "Kategorie: science_fiction\n",
      "Mittelwert: 2411.6666666666665\n",
      "Standardabweichung: 46.87809249058194\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import sys\n",
    "\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.append(\"..\")\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from common.corpus import CorpusLoader\n",
    "from common.visualization import hbar_plot\n",
    "\n",
    "# Laden des Brown Corpus\n",
    "CorpusLoader.load()\n",
    "brown = CorpusLoader.brown_corpus()\n",
    "brown_categories = brown.categories()\n",
    "\n",
    "for cat in brown_categories:\n",
    "    print(f'\\nKategorie: {cat}')\n",
    "    word_amount_list = []\n",
    "    for doc in brown.fileids(cat):\n",
    "        word_amount_list.append(len(brown.words(fileids=doc)))\n",
    "        #print(len(brown.words(fileids=doc)))\n",
    "        \n",
    "    print(f'Mittelwert: {np.mean(word_amount_list)}')\n",
    "    print(f'Standardabweichung: {np.std(word_amount_list)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d714460e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " ## Klassifikation von Dokumenten\n",
    "\n",
    "Nachdem Sie sich nun mit der Struktur und den Eigenschaften des Brown Corpus vertraut gemacht haben, soll er die Datengrundlage fuer die Evaluierung von Algorithmen zur automatischen Klassifikation von Dokumenten bilden.\n",
    "In der Regel bestehen diese Algorithmen aus drei Schritten:\n",
    " - Vorverarbeitung\n",
    " - Merkmalsberechnung\n",
    " - Klassifikation\n",
    "\n",
    "Bei der Anwendung auf Dokumente (Texte) werden diese Schritte wie folgt umgesetzt:\n",
    "\n",
    " - **Vorverarbeitung:** Filterung von stopwords und Abbildung von Woertern auf Wortstaemme.\n",
    " - **Merkmalsberechnung:** Jedes Dokument wird numerisch durch einen Vektor repraesentiert (--> NumPy), der moeglichst die bzgl. der Klassifikation bedeutungsunterscheidenden Informationen enthaehlt.\n",
    " - **Klassifikation:** Jedem Merkmalsvektor (Dokument) wird ein Klassenindex (Kategorie) zugeordnet.\n",
    "\n",
    "Details finden Sie zum Beispiel in:\n",
    "http://www5.informatik.uni-erlangen.de/fileadmin/Persons/NiemannHeinrich/klassifikation-von-mustern/m00-www.pdf (section 1.3)\n",
    "\n",
    "Eine sehr verbreitete Merkmalsrepraesentation fuer (textuelle) Dokumente sind sogenannte Bag-of-Words. Dabei wird jedes Dokument durch ein Histogram (Verteilung) ueber Wortfrequenzen repraesentiert. Man betrachtet dazu das Vorkommen von 'typischen' Woertern, die durch ein Vokabular gegeben sind.\n",
    "\n",
    "Bestimmen Sie ein Vokabular, also die typischen Woerter, fuer den Brown Corpus. Berechnen Sie dazu die 500 haeufigsten Woerter (nach stemming und Filterung von stopwords und Satzzeichen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d1ec590",
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a0fce63b22774c21838df9c237c278a",
     "grade": true,
     "grade_id": "cell-20249d0f7471c4a7",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering and stemming words in corpus...\n",
      "Building Bag-of-Words vocabulary...\n",
      "['one', 'would', 'said', 'time', 'new', 'year', 'could', 'like', 'state', 'use', 'may', 'two', 'first', 'even', 'make', 'man', 'work', 'made', 'day', 'also', 'way', 'mani', 'go', 'look', 'must', 'back', 'af', 'get', 'come', 'much', 'well', 'see', 'peopl', 'good', 'take', 'mr.', 'seem', 'know', 'gener', 'littl', 'place', 'say', 'world', 'still', 'hand', 'long', 'men', 'nation', 'hous', 'life', 'develop', 'need', 'call', 'last', 'thing', 'right', 'never', 'school', 'unit', 'anoth', 'great', 'us', 'might', 'turn', 'mean', 'old', 'american', 'want', 'point', 'sinc', 'part', 'came', 'home', 'three', 'number', 'ask', 'think', 'interest', 'give', 'thought', 'differ', 'person', 'form', 'live', 'follow', 'show', 'without', 'present', 'found', 'end', 'provid', 'possibl', 'around', 'open', 'area', 'problem', 'head', 'word', 'program', 'howev', 'public', 'system', 'find', 'set', 'small', 'eye', 'effect', 'mrs.', 'fact', 'group', 'face', 'cours', '1', 'govern', 'plan', 'becom', 'import', 'order', 'line', 'put', 'case', 'chang', 'forc', 'went', 'name', 'move', 'high', 'citi', 'water', 'upon', 'feel', 'war', 'everi', 'continu', 'result', 'tri', 'side', 'increas', 'help', 'commun', 'offic', 'power', 'got', 'left', 'countri', 'play', 'oper', 'busi', 'experi', 'studi', 'reason', 'member', 'servic', 'question', 'alway', 'away', 'toward', 'requir', 'someth', 'sever', 'report', 'start', 'complet', '2', 'night', 'church', 'room', 'close', 'though', 'less', 'light', 'almost', 'enough', 'larg', 'took', 'natur', 'social', 'far', 'includ', 'appear', 'presid', 'let', 'yet', 'better', 'week', 'told', 'noth', 'cost', 'famili', 'act', 'second', 'valu', 'later', 'knew', 'next', 'direct', 'product', 'run', 'mind', 'law', 'white', 'car', 'young', 'boy', 'posit', 'given', 'expect', 'compani', 'matter', 'inform', 'rather', 'univers', 'meet', 'per', 'often', 'among', 'industri', 'john', 'final', 'earli', 'love', 'return', 'polit', 'girl', 'four', 'big', 'within', 'action', 'felt', 'saw', 'activ', 'along', 'kind', 'children', 'figur', 'tell', 'individu', 'best', 'human', 'sens', 'organ', 'field', 'door', 'read', 'care', 'keep', 'believ', 'exampl', 'ever', 'student', 'leav', 'least', 'reach', 'bodi', 'probabl', 'consid', 'rate', 'idea', 'pass', 'concern', 'period', 'talk', 'educ', 'miss', 'god', 'measur', 'build', 'respons', 'control', 'walk', 'hope', 'type', 'remain', 'other', 'determin', 'design', 'although', 'local', 'record', 'hour', 'done', 'month', 'stand', 'whole', 'level', 'certain', 'exist', 'began', 'thu', 'begin', 'receiv', 'object', 'major', 'sure', 'indic', 'condit', 'music', 'process', 'train', 'carri', 'perhap', 'book', 'colleg', 'moment', 'street', 'job', 'relat', 'usual', 'serv', 'recent', 'york', 'quit', 'age', 'practic', 'past', 'step', 'sound', 'econom', 'caus', 'histori', 'method', 'board', 'center', 'friend', 'special', 'support', 'class', 'subject', 'note', 'evid', 'polici', 'cut', 'five', 'land', 'materi', '3', 'whether', 'happen', 'death', 'gave', 'either', 'today', 'court', 'art', 'feet', 'addit', 'understand', 'across', 'taken', 'anyth', 'hold', 'success', 'seen', 'write', 'answer', 'depart', 'societi', 'wait', 'arm', 'parti', 'half', 'realli', 'avail', 'except', 'actual', 'manag', 'alreadi', 'effort', 'fire', 'issu', 'view', 'stop', 'town', 'learn', 'suggest', \"i'm\", 'voic', 'money', 'togeth', 'shall', 'tax', 'accept', 'situat', 'involv', 'letter', 'feder', 'held', 'free', 'air', 'associ', 'clear', 'section', 'perform', 'real', 'behind', 'term', 'cover', 'author', 'cannot', 'total', 'produc', 'establish', 'road', 'allow', 'color', 'brought', 'express', 'purpos', 'million', 'centuri', 'minut', 'ground', 'rememb', 'whose', 'repres', 'test', 'heard', 'hear', 'ago', 'becam', 'watch', 'known', 'respect', 'stage', 'limit', 'tabl', 'short', 'mother', 'south', 'entir', 'observ', 'discuss', 'market', 'offer', 'pictur', 'base', 'bring', 'rang', 'west', 'prepar', 'intern', 'administr', 'full', 'spirit', 'sometim', 'front', 'wall', 'charg', 'lead', 'true', 'common', 'surfac', 'modern', 'wife', 'peac', 'dark', 'futur', 'consider', 'top', 'woman', 'necessari', 'claim', 'pressur', 'properti', 'amount', 'mile', 'morn', 'approach', 'outsid', 'piec', 'rest', 'six', 'list', 'wonder', 'demand', 'beauti', 'achiev', 'ad', 'abl', 'near', 'pay', 'black', 'hundr', 'rule', 'child', 'enter', 'origin', 'stori', 'institut', 'stood', 'fall', 'militari', 'fear', 'union', 'stay', 'appli', 'space', 'mark', 'statement', 'deal']\n"
     ]
    }
   ],
   "source": [
    "from common.features import BagOfWords, WordListNormalizer\n",
    "import itertools\n",
    "# vocabulary =\n",
    "\n",
    "print('Filtering and stemming words in corpus...')\n",
    "normalizer = WordListNormalizer()\n",
    "category_wordlists_dict = normalizer.category_wordlists_dict(corpus=brown)\n",
    "# Flatten the category word lists for computing overall word frequencies\n",
    "# The * operator expands the list/iterator to function arguments\n",
    "# itertools.chain concatenates all its parameters to a single list\n",
    "print('Building Bag-of-Words vocabulary...')\n",
    "wordlists = itertools.chain(*(iter(category_wordlists_dict.values())))\n",
    "words = itertools.chain(*wordlists)\n",
    "\n",
    "vocabulary_complete = BagOfWords.most_freq_words(words)\n",
    "vocabulary = vocabulary_complete[:500]\n",
    "\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b72152",
   "metadata": {},
   "source": [
    "Berechnen Sie Bag-of-Words Repraesentationen fuer jedes Dokument des Brown Corpus. Verwenden Sie absolute Frequenzen. speichern Sie die Bag-of-Word Repraesentationen fuer jede Kategorie in einem 2-D NumPy Array. Speichern Sie den Bag-of-Words Vektor fuer jedes Dokument in einer Zeile, so dass das Array (ndarray) folgende Dimension hat:\n",
    "\n",
    " |Dokument_kat| X |Vokabular|\n",
    "\n",
    "|Dokument_kat| entspricht der Anzahl Dokumente einer Kategorie.\n",
    "|Vokabular| entspricht der Anzahl Woerter im Vokabular (hier 500).\n",
    "\n",
    "Eine einfache Zuordnung von Kategorie und Bag-of-Words Matrix ist durch ein Dictionary moeglich.\n",
    "\n",
    "Implementieren Sie die Funktion BagOfWords.category_bow_dict im Modul features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c6a448",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Bag-of-Words feature vector representations...\n"
     ]
    }
   ],
   "source": [
    "print('Building Bag-of-Words feature vector representations...')\n",
    "bow = BagOfWords(vocabulary)\n",
    "category_bow_dict = bow.category_bow_dict(category_wordlists_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015388d9",
   "metadata": {},
   "source": [
    "Testen Sie ihre Implementierung mit folgendem Unittest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b819907",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.064s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "from utest.test_features import BagOfWordsTest\n",
    "\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTest(BagOfWordsTest(\"test_category_bow_dict\"))\n",
    "runner = unittest.TextTestRunner()\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6cf999",
   "metadata": {},
   "source": [
    "Um einen Klassifikator statistisch zu evaluieren, benoetigt man eine Trainingsstichprobe und eine Teststichprobe der Daten die klassifiziert werden sollen. Die Trainingsstichprobe benoetigt man zum Erstellen oder Trainieren des Klassifikators. Dabei werden in der Regel die Modellparameter des Klassifikators statistisch aus den Daten der Traingingsstichprobe geschaetzt. Die Klassenzugehoerigkeiten sind fuer die Beispiele aus der Trainingsstichprobe durch so genannte Klassenlabels gegeben.\n",
    "\n",
    "Nachdem man den Klassifikator trainiert hat, interessiert man sich normalerweise dafuer wie gut er sich unter realen Bedingung verhaelt. Das heisst, dass der Klassifikator bei der Klassifikation zuvor unbekannter Daten moeglichst wenige Fehler machen soll. Dies simuliert man mit der Teststichprobe. Da auch fuer jedes Beispiel aus der Teststichprobe die Klassenzugehoerigkeit bekannt ist, kann man am Ende die Klassifikationsergebnisse mit den wahren Klassenlabels (aus der Teststichprobe) vergleichen und eine Fehlerrate angeben.\n",
    "\n",
    "In dem gegebenen Brown Corpus ist keine Aufteilung in Trainings und Testdaten vorgegeben.\n",
    "\n",
    "Waehlen Sie daher die ersten 80% der Dokumente UEBER ALLE KATEGORIEN als Trainingstichprobe und die letzten 20% der Dokumente UEBER ALLE KATEGORIEN als Teststichprobe.\n",
    "\n",
    "Erklaeren Sie, warum Sie die Stichproben ueber alle Kategorien zusammenstellen MUESSEN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cd2cd",
   "metadata": {},
   "source": [
    "**Antwort:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f777aa9",
   "metadata": {},
   "source": [
    "Bitte beachten Sie, dass wir im Rahmen des Fachprojekts keinen Test auf unbekannten Testdaten simulieren. Wir haben ja bereits fuer die Erstellung der Vokabulars (haeufigste Woerter, siehe oben) den kompletten Datensatz verwendet. Stattdessen betrachten wir hier ein so genanntes Validierungsszenario, in dem wir die Klassifikationsleistung auf dem Brown Corpus optimieren. Die Ergebnisse lassen sich somit nur sehr bedingt auf unbekannte Daten uebertragen.\n",
    "\n",
    "Erstellen Sie nun die NumPy Arrays train_samples, train_labels, test_samples und test_labels, so dass diese mit den estimate und classify Methoden der Klassen im classificaton Modul verwendet werden koennen. Teilen Sie die Daten wie oben angegeben zu 80% in Trainingsdaten und 20% in Testdaten auf.\n",
    "\n",
    "Hinweis: Vollziehen Sie nach, wie die Klasse CrossValidation im evaluation Modul funktioniert. Wenn Sie moechten, koennen die Klasse zur Aufteilung der Daten verwenden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce66684d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1992869a",
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8dcef3fbe66046e704e490bf25e6653",
     "grade": true,
     "grade_id": "cell-710dd0d66faa5a19",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from common.evaluation import CrossValidation\n",
    "cross_val = CrossValidation(category_bow_dict, 5)\n",
    "fold_data = cross_val.corpus_fold(1)\n",
    "\n",
    "# Trainings- und Testdaten extrahieren\n",
    "train_bow = fold_data[0]\n",
    "test_bow = fold_data[2]\n",
    "train_labels = fold_data[1]\n",
    "test_labels = fold_data[3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec389a",
   "metadata": {},
   "source": [
    "Klassifizieren Sie nun alle Dokumente der Teststichprobe nach dem Prinzip des k-naechste-Nachbarn Klassifikators. Dabei wird die Distanz zwischen dem Merkmalsvektors eines Testbeispiels und allen Merkmalsvektoren aus der Trainingstichprobe berechnet. Das Klassenlabel des Testbeispiels wird dann ueber einen Mehrheitsentscheid der Klassenlabels der k aehnlichsten Merkmalsvektoren aus der Trainingsstichprobe bestimmt.\n",
    "\n",
    "http://www5.informatik.uni-erlangen.de/fileadmin/Persons/NiemannHeinrich/klassifikation-von-mustern/m00-www.pdf (Abschnitt 4.2.7)\n",
    "\n",
    "Bestimmen Sie die Distanzen von Testdaten zu Trainingsdaten mit cdist:\n",
    "http://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html\n",
    "Bestimmen Sie die k-naechsten Nachbarn auf Grundlage der zuvor berechneten Distanzen mit argsort:\n",
    "http://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html\n",
    "Ueberlegen Sie, welche zuvor von Ihnen implementierte Funktion Sie wiederverwenden koennen, um den Mehrheitsentscheid umzusetzen.\n",
    "\n",
    "Implementieren Sie die Funktionen estimate und classify in der Klasse KNNClassifier im Modul classification.\n",
    "\n",
    "Verwenden Sie die Euklidische Distanz und betrachten Sie zunaechst nur den naechsten Nachbarn (k=1).\n",
    "\n",
    "HINWEIS: Hier ist zunaechst nur die Implementierung eines naechster Nachbar Klassifikators erforderlich. Diese soll aber in der naechsten Aufgabe zu einer Implementierung eines k-naechste Nachbarn Klassifikators erweitert werden. Beruechsichtigen Sie das in ihrer Implementierung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5febd5ca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from common.classification import KNNClassifier\n",
    "\n",
    "knn_classifier = KNNClassifier(k_neighbors=1, metric='euclidean')\n",
    "knn_classifier.estimate(train_bow, train_labels)\n",
    "knn_test_labels = knn_classifier.classify(test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1af3b86",
   "metadata": {},
   "source": [
    "Testen Sie ihre Implementierung mit folgendem Unittest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b2cc525",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "from utest.test_classification import ClassificationTest\n",
    "\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTest(ClassificationTest(\"test_nn\"))\n",
    "runner = unittest.TextTestRunner()\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b861eb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Nachdem Sie mit dem KNNClassifier fuer jedes Testbeispiel ein Klassenlabel geschaetzt haben, koennen Sie dieses mit dem tatsaechlichen Klassenlabel vergleichen. Dieses koennen Sie wie bei den Traingingsdaten dem Corpus entnehmen.\n",
    "\n",
    "Ermitteln Sie eine Gesamtfehlerrate und je eine Fehlerrate pro Kategorie. Implementieren Sie dazu die Klasse ClassificationEvaluator im evaluation Modul.\n",
    "\n",
    "Warum ist diese Aufteilung der Daten in Training und Test problematisch? Was sagen die Ergebnisse aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75dbae39",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5887/2668247396.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassificationEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassification_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_test_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_wrong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sampels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcategory_error_rates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_error_rates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fpda/aufgabe02/../common/evaluation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, estimated_labels, groundtruth_labels)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# Labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from common.evaluation import ClassificationEvaluator\n",
    "\n",
    "classification_eval = ClassificationEvaluator(knn_test_labels, test_labels)\n",
    "err, n_wrong, n_sampels = classification_eval.error_rate()\n",
    "category_error_rates = classification_eval.category_error_rates()\n",
    "print('Classification error rates: ( n_wrong, n_samples ) error_rate')\n",
    "print('   Overall        : ( {:2} / {:2} ) {:.2f}'.format(n_wrong, n_sampels, err))\n",
    "print('Class specific :')\n",
    "for category, err, n_wrong, n_samples in category_error_rates:\n",
    "    print('   {:15}: ( {:2} / {:2} ) {:.2f}'.format(category, n_wrong, n_samples, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a6908",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Testen Sie ihre Implementierung mit folgendem Unittest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5de894ed",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EE\n",
      "======================================================================\n",
      "ERROR: test_category_error_rates (utest.test_evaluation.ClassificationEvaluatorTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/fpda/aufgabe02/../utest/test_evaluation.py\", line 34, in test_category_error_rates\n",
      "    class_eval = ClassificationEvaluator(self.__estimated_labels, self.__gt_labels)\n",
      "  File \"/home/jovyan/fpda/aufgabe02/../common/evaluation.py\", line 131, in __init__\n",
      "    raise NotImplementedError()\n",
      "NotImplementedError\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_error_rate (utest.test_evaluation.ClassificationEvaluatorTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/fpda/aufgabe02/../utest/test_evaluation.py\", line 16, in test_error_rate\n",
      "    class_eval = ClassificationEvaluator(self.__estimated_labels, self.__gt_labels)\n",
      "  File \"/home/jovyan/fpda/aufgabe02/../common/evaluation.py\", line 131, in __init__\n",
      "    raise NotImplementedError()\n",
      "NotImplementedError\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.002s\n",
      "\n",
      "FAILED (errors=2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fd008ce36d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "from utest.test_evaluation import ClassificationEvaluatorTest\n",
    "unittest.main(ClassificationEvaluatorTest(), argv=[''], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20e570-7061-485c-a8ec-6e93325e7048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
